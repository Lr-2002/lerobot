#!/usr/bin/env python3
"""
ç®€åŒ–çš„æ•°æ®æ”¶é›†å™¨
æ”¯æŒåŸºæœ¬çš„å¤šçº¿ç¨‹æ•°æ®æ”¶é›†å’Œè§†é¢‘å­˜å‚¨
"""

import threading
import time
import signal
import json
import numpy as np
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, Any, Callable, Optional, List
import h5py
import tempfile
import shutil
from PIL import Image
import subprocess
import os
from collections import defaultdict
from datetime import datetime

@dataclass
class DataSourceConfig:
    """æ•°æ®æºé…ç½®"""
    name: str
    callback: Callable[[], Any]
    frequency: float = 30.0  # Hz
    enabled: bool = True
    is_image: bool = False  # æ˜¯å¦ä¸ºå›¾åƒæ•°æ®æº

@dataclass
class VideoConfig:
    """è§†é¢‘ç¼–ç é…ç½®"""
    enabled: bool = True  # å¯ç”¨è§†é¢‘ç¼–ç 
    codec: str = "libx264"  # è§†é¢‘ç¼–ç å™¨: libx264, libx265, libsvtav1
    pixel_format: str = "yuv420p"  # åƒç´ æ ¼å¼
    crf: int = 23  # æ’å®šè´¨é‡å› å­ (0=æ— æŸ, 51=æœ€å·®è´¨é‡)
    fps: int = 30  # è§†é¢‘å¸§ç‡
    keyframe_interval: int = 2  # å…³é”®å¸§é—´éš”

class SimpleDataCollector:
    """ç®€åŒ–çš„æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, fps: int = 30, dataset_name: str = "robot_data", output_dir: str = "./data", 
                 video_config: Optional[VideoConfig] = None):
        self.fps = fps
        self.dataset_name = dataset_name
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.default_frequency = fps
        self.video_config = video_config or VideoConfig()
        self.data_sources: Dict[str, DataSourceConfig] = {}
        self.collected_data: Dict[str, List] = {}
        self.timestamps: Dict[str, List] = {}
        self.threads: Dict[str, threading.Thread] = {}
        self.stop_event = threading.Event()
        self.data_lock = threading.Lock()
        self.is_collecting = False
        
        # For video storage
        self.temp_image_dirs: Dict[str, Path] = {}  # Temporary directories for images
        self.image_counters: Dict[str, int] = {}  # Frame counters for each image source
        
        # Setup signal handler for graceful shutdown
        signal.signal(signal.SIGINT, self._signal_handler)
        
        print(f"ğŸ¤– æ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ - FPS: {fps}, æ•°æ®é›†: {dataset_name}")
        if self.video_config.enabled:
            print(f"ğŸ¥ è§†é¢‘ç¼–ç : å¯ç”¨ ({self.video_config.codec}, CRF={self.video_config.crf})")
    
    def _signal_handler(self, signum, frame):
        """å¤„ç†Ctrl+Cä¿¡å·"""
        print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        self.stop()
    
    def register_data_source(self, name: str, callback: Callable[[], Any], 
                           frequency: float = None, is_image: bool = False):
        """æ³¨å†Œæ•°æ®æº"""
        if frequency is None:
            frequency = self.default_frequency
            
        config = DataSourceConfig(
            name=name,
            callback=callback,
            frequency=frequency,
            is_image=is_image
        )
        
        self.data_sources[name] = config
        self.collected_data[name] = []
        self.timestamps[name] = []
        
        if is_image and self.video_config.enabled:
            # Create temporary directory for image frames
            temp_dir = Path(tempfile.mkdtemp(prefix=f"images_{name}_"))
            self.temp_image_dirs[name] = temp_dir
            self.image_counters[name] = 0
            print(f"ğŸ“· æ³¨å†Œå›¾åƒæ•°æ®æº '{name}' @ {frequency} Hz (è§†é¢‘ç¼–ç )")
        else:
            print(f"ğŸ“Š æ³¨å†Œæ•°æ®æº '{name}' @ {frequency} Hz")
    
    def _collect_data_thread(self, source_name: str):
        """æ•°æ®æ”¶é›†çº¿ç¨‹"""
        config = self.data_sources[source_name]
        interval = 1.0 / config.frequency
        
        print(f"ğŸ”„ å¼€å§‹æ”¶é›† '{source_name}' @ {config.frequency} Hz")
        
        while not self.stop_event.is_set():
            start_time = time.time()
            
            try:
                # Get data from callback
                data = config.callback()
                timestamp = time.time()
                
                if config.is_image and self.video_config.enabled:
                    # Save image to temporary file
                    self._save_image_frame(source_name, data, timestamp)
                else:
                    # Store data in memory
                    with self.data_lock:
                        self.collected_data[source_name].append(data)
                        self.timestamps[source_name].append(timestamp)
                
            except Exception as e:
                print(f"âŒ æ•°æ®æº '{source_name}' é”™è¯¯: {e}")
            
            # Sleep for the remaining time
            elapsed = time.time() - start_time
            sleep_time = max(0, interval - elapsed)
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        print(f"âœ… '{source_name}' çº¿ç¨‹å·²åœæ­¢")
    
    def _save_image_frame(self, source_name: str, image_data: np.ndarray, timestamp: float):
        """ä¿å­˜å›¾åƒå¸§åˆ°ä¸´æ—¶æ–‡ä»¶"""
        try:
            # Convert numpy array to PIL Image
            if isinstance(image_data, np.ndarray):
                if image_data.dtype != np.uint8:
                    image_data = (image_data * 255).astype(np.uint8)
                
                if len(image_data.shape) == 3:
                    image = Image.fromarray(image_data)
                else:
                    image = Image.fromarray(image_data, mode='L')
            else:
                image = image_data
            
            # Save to temporary directory
            frame_idx = self.image_counters[source_name]
            temp_dir = self.temp_image_dirs[source_name]
            image_path = temp_dir / f"frame_{frame_idx:06d}.jpg"
            
            image.save(image_path, "JPEG", quality=95)
            
            # Store timestamp
            with self.data_lock:
                self.timestamps[source_name].append(timestamp)
            
            self.image_counters[source_name] += 1
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å›¾åƒå¸§å¤±è´¥ '{source_name}': {e}")
    
    def start(self):
        """å¼€å§‹æ•°æ®æ”¶é›†"""
        if self.is_collecting:
            print("âš ï¸ æ•°æ®æ”¶é›†å·²åœ¨è¿›è¡Œä¸­")
            return
        
        self.is_collecting = True
        self.stop_event.clear()
        
        print("ğŸš€ å¼€å§‹æ•°æ®æ”¶é›†...")
        
        # Start collection threads
        for source_name in self.data_sources:
            thread = threading.Thread(
                target=self._collect_data_thread,
                args=(source_name,),
                daemon=False  # Changed to False to ensure proper cleanup
            )
            thread.start()
            self.threads[source_name] = thread
        
        print(f"âœ… å¯åŠ¨äº† {len(self.threads)} ä¸ªæ•°æ®æ”¶é›†çº¿ç¨‹")
    
    def stop(self):
        """åœæ­¢æ•°æ®æ”¶é›†"""
        if not self.is_collecting:
            print("âš ï¸ æ•°æ®æ”¶é›†æœªåœ¨è¿›è¡Œ")
            return
        
        print("ğŸ›‘ åœæ­¢æ•°æ®æ”¶é›†...")
        self.stop_event.set()
        
        # Wait for all threads to finish
        for source_name, thread in self.threads.items():
            if thread.is_alive():
                thread.join(timeout=3.0)
                if thread.is_alive():
                    print(f"âš ï¸ çº¿ç¨‹ '{source_name}' æœªèƒ½æ­£å¸¸åœæ­¢")
        
        self.is_collecting = False
        
        # Process and save data
        self._save_data()
        
        print("âœ… æ•°æ®æ”¶é›†å·²åœæ­¢")
    
    def _save_data(self):
        """ä¿å­˜æ”¶é›†çš„æ•°æ®"""
        timestamp = int(time.time())
        
        # Encode videos for image sources
        if self.video_config.enabled:
            self._encode_videos()
        
        # Save non-image data to HDF5
        h5_path = self.output_dir / f"data_{timestamp}.h5"
        self._save_hdf5_data(h5_path)
        
        # Save metadata
        metadata_path = self.output_dir / f"metadata_{timestamp}.json"
        self._save_metadata(metadata_path)
        
        # Cleanup temporary directories
        self._cleanup_temp_dirs()
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° {self.output_dir}")
    
    def _encode_videos(self):
        """ç¼–ç è§†é¢‘æ–‡ä»¶"""
        print("ğŸ¬ å¼€å§‹è§†é¢‘ç¼–ç ...")
        
        for source_name, temp_dir in self.temp_image_dirs.items():
            if not temp_dir.exists():
                continue
                
            # Count frames
            frame_files = list(temp_dir.glob("frame_*.jpg"))
            if len(frame_files) == 0:
                continue
            
            print(f"ğŸ¥ ç¼–ç  '{source_name}' -> {source_name}.mp4")
            
            # Calculate original size
            original_size = sum(f.stat().st_size for f in frame_files)
            
            # Encode video using ffmpeg
            video_path = self.output_dir / f"{source_name}.mp4"
            self._run_ffmpeg_encoding(temp_dir, video_path)
            
            # Calculate compression ratio
            if video_path.exists():
                compressed_size = video_path.stat().st_size
                ratio = original_size / compressed_size if compressed_size > 0 else 1
                print(f"âœ… '{source_name}' è§†é¢‘ç¼–ç å®Œæˆ")
                print(f"   å‹ç¼©æ¯”: {ratio:.1f}x ({original_size/1024/1024:.1f}MB -> {compressed_size/1024/1024:.1f}MB)")
    
    def _run_ffmpeg_encoding(self, input_dir: Path, output_path: Path):
        """è¿è¡Œffmpegç¼–ç """
        try:
            cmd = [
                "ffmpeg", "-y",  # Overwrite output
                "-framerate", str(self.video_config.fps),
                "-i", str(input_dir / "frame_%06d.jpg"),
                "-c:v", self.video_config.codec,
                "-crf", str(self.video_config.crf),
                "-pix_fmt", self.video_config.pixel_format,
                "-g", str(self.video_config.keyframe_interval),
                str(output_path)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"âŒ ffmpegç¼–ç å¤±è´¥: {result.stderr}")
                
        except Exception as e:
            print(f"âŒ è§†é¢‘ç¼–ç é”™è¯¯: {e}")
    
    def _save_hdf5_data(self, h5_path: Path):
        """ä¿å­˜éå›¾åƒæ•°æ®åˆ°HDF5"""
        try:
            with h5py.File(h5_path, 'w') as f:
                for source_name, data_list in self.collected_data.items():
                    config = self.data_sources[source_name]
                    
                    # Skip image sources (they are saved as videos)
                    if config.is_image and self.video_config.enabled:
                        continue
                    
                    if len(data_list) == 0:
                        continue
                    
                    # Convert to numpy array
                    try:
                        data_array = np.array(data_list)
                        timestamps_array = np.array(self.timestamps[source_name])
                        
                        # Create group for this data source
                        group = f.create_group(source_name)
                        group.create_dataset('data', data=data_array)
                        group.create_dataset('timestamps', data=timestamps_array)
                        
                    except Exception as e:
                        print(f"âš ï¸ æ— æ³•ä¿å­˜æ•°æ®æº '{source_name}': {e}")
                        
        except Exception as e:
            print(f"âŒ ä¿å­˜HDF5æ–‡ä»¶å¤±è´¥: {e}")
    
    def _save_metadata(self, metadata_path: Path):
        """ä¿å­˜å…ƒæ•°æ®"""
        metadata = {
            "collection_time": int(time.time()),
            "dataset_name": self.dataset_name,
            "video_config": {
                "enabled": self.video_config.enabled,
                "codec": self.video_config.codec,
                "crf": self.video_config.crf,
                "fps": self.video_config.fps
            } if self.video_config.enabled else None,
            "data_sources": {}
        }
        
        for source_name, config in self.data_sources.items():
            if config.is_image and self.video_config.enabled:
                sample_count = self.image_counters.get(source_name, 0)
            else:
                sample_count = len(self.collected_data.get(source_name, []))
            
            metadata["data_sources"][source_name] = {
                "frequency": config.frequency,
                "is_image": config.is_image,
                "sample_count": sample_count
            }
        
        try:
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f, indent=2)
        except Exception as e:
            print(f"âŒ ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
    
    def _cleanup_temp_dirs(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        for source_name, temp_dir in self.temp_image_dirs.items():
            if temp_dir.exists():
                try:
                    shutil.rmtree(temp_dir)
                    print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥ {temp_dir}: {e}")
    
    def run_for_duration(self, duration: float):
        """è¿è¡ŒæŒ‡å®šæ—¶é—´"""
        self.start()
        print(f"ğŸ’¤ æ”¶é›†æ•°æ® {duration} ç§’...")
        
        # Wait for the specified duration
        start_time = time.time()
        while time.time() - start_time < duration and self.is_collecting:
            time.sleep(0.1)
        
        self.stop()
    
    def run_forever(self):
        """æŒç»­è¿è¡Œç›´åˆ°Ctrl+C"""
        self.start()
        print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢æ”¶é›†")
        try:
            while self.is_collecting:
                time.sleep(0.1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·...")
        finally:
            if self.is_collecting:
                self.stop()
    
    def get_stats(self):
        """è·å–æ”¶é›†ç»Ÿè®¡"""
        stats = {}
        total_samples = 0
        
        for source_name, config in self.data_sources.items():
            if config.is_image and self.video_config.enabled:
                count = self.image_counters.get(source_name, 0)
            else:
                count = len(self.collected_data.get(source_name, []))
            
            stats[source_name] = count
            total_samples += count
        
        return stats, total_samples


# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # æ¨¡æ‹Ÿæ•°æ®æº
    def get_mock_image():
        """æ¨¡æ‹Ÿç›¸æœºæ•°æ®"""
        return np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    def get_mock_sensor():
        """æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®"""
        return np.random.randn(6).tolist()
    
    # åˆ›å»ºæ”¶é›†å™¨
    video_config = VideoConfig(
        enabled=True,
        codec="libx264",
        crf=23,
        fps=30
    )
    
    collector = SimpleDataCollector(
        fps=30,
        dataset_name="test_data",
        output_dir="./simple_data",
        video_config=video_config
    )
    
    # æ³¨å†Œæ•°æ®æº
    collector.register_data_source("camera", get_mock_image, frequency=30, is_image=True)
    collector.register_data_source("sensors", get_mock_sensor, frequency=100, is_image=False)
    
    print("\nğŸ¬ ç®€åŒ–æ•°æ®æ”¶é›†å™¨æ¼”ç¤º")
    print("ğŸ’¡ å°†æ”¶é›†3ç§’æ•°æ®ï¼Œç„¶åè‡ªåŠ¨åœæ­¢")
    
    # è¿è¡Œ3ç§’
    collector.run_for_duration(3.0)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    stats, total = collector.get_stats()
    print(f"\nğŸ“Š æ”¶é›†ç»Ÿè®¡:")
    for name, count in stats.items():
        print(f"  {name}: {count} ä¸ªæ ·æœ¬")
    print(f"  æ€»è®¡: {total} ä¸ªæ ·æœ¬")
